{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "\n",
    "\n",
    "## epoch, batch size, iteration\n",
    "\n",
    "* One **epoch** includes passing entire training dataset to network: one forward pass + one backpropagation pass. \n",
    "\n",
    "* The **batch size** is the number of samples included in a batch, that will be feeded into the network at once.\n",
    "\n",
    "* An **iteration number** is the number of times you have to feed batch data into network to finish entire training data.\n",
    "\n",
    "The relationship can be summarized as:\n",
    "\n",
    "```\n",
    "total # of samples = iteration * batch size\n",
    "```\n",
    "\n",
    "\n",
    "## The general form of training \n",
    "\n",
    "```\n",
    "for i in range(# of epoches):\n",
    "    for j in range(# of batches)\n",
    "        ...\n",
    "        model(this_batch)\n",
    "        ...\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy\n",
    "\n",
    "Let's say you have a CSV file, last column is the label, numpy can load the data as the following.\n",
    "\n",
    "\n",
    "```\n",
    "xy = np.loadtxt(\"sample_data.csv\", delimiter=',', dtype=np.float32)\n",
    "x_data = Variable(torch.from_numpy(xy[:, 0:-1])) # all rows, all columns except last one \n",
    "y_data = Variable(torch.from_numpy(xy[:, [-1]])) # all rows, only last column \n",
    "\n",
    "for epoch in range(10):\n",
    "    y_pred = model(x_data)\n",
    "    ...\n",
    "```\n",
    "\n",
    "Here, if you don't want to or **can't** feed all data into network all at once, you have to manually put them into batches. \n",
    "\n",
    "pytorch provided some utility function to simplify the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch\n",
    "\n",
    "\n",
    "### define cutomized dataset \n",
    "\n",
    "```\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \"\"\" download and read data \"\"\"\n",
    "        xy = np.loadtxt(\"sample_data.csv\", delimiter=',', dtype=np.float32)\n",
    "        self.len = xy.shape[0]\n",
    "        self.x_data = torch.from_numpy(xy[:, 0:-1])\n",
    "        self.y_data = torch.from_numpy(xy[:, [-1]]) \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Given index, return data \"\"\"\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len \n",
    "```\n",
    "\n",
    "### wrap it into DataLoader\n",
    "\n",
    "```\n",
    "dataset = MyDataset()\n",
    "train_loader = DataLoader(dataset = dataset,\n",
    "                            batch_size = 32,\n",
    "                            shuffle = True,\n",
    "                            num_workers = 2)\n",
    "```\n",
    "\n",
    "### use it \n",
    "\n",
    "```\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        y_pred = model(inputs)\n",
    "\n",
    "        ...\n",
    "...\n",
    "```\n"
   ]
  }
 ]
}