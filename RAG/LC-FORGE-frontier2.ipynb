{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402974cb-7934-4c81-a44a-e603ca7c4852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GPTNeoXForCausalLM, GPTNeoXTokenizerFast\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "loader = TextLoader('frontier.txt')\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7533a8dc-6079-4845-af1e-fc8611e76c0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using FORGE-S embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7885e0a4-7cef-400c-ba1d-8a9d39db2bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models,util\n",
    "from transformers import AutoTokenizer\n",
    "model_path = \"/proj/f7b/forge-s-instruct-base1\"\n",
    "word_embedding_model = models.Transformer(model_path, max_seq_length=512)\n",
    "word_embedding_model.tokenizer.pad_token=word_embedding_model.tokenizer.eos_token\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9861464e-cc3e-4392-a70e-e1bd71811aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2064"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding_model.get_word_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cda3a485-3832-4060-988e-b719be15a4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5146]])\n",
      "tensor([[0.8933]])\n",
      "tensor([[1.]])\n"
     ]
    }
   ],
   "source": [
    "e1=model.encode(\"I am a happy person\")\n",
    "e2=model.encode(\"the sky is falling\")\n",
    "e3=model.encode(\"I am a sad person\")\n",
    "e4=model.encode(\"I am a happy person\")\n",
    "print(util.cos_sim(e1, e2))\n",
    "print(util.cos_sim(e1, e3))\n",
    "print(util.cos_sim(e1, e4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06eb98d6-7e69-442b-b012-119cfbd52f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[42.8058, 51.4530, 49.7797, 31.9822, 40.4576]])\n",
      "Similarity: tensor([[0.5587, 0.6040, 0.5475, 0.5262, 0.5752]])\n"
     ]
    }
   ],
   "source": [
    "query_embedding = model.encode('what is the cpu type on frontier')\n",
    "texts_embedding = model.encode([\n",
    "    \"\"\"scheduling policy of frontier is that in a simple batch queue system, jobs run in a first-in, first-out (FIFO) order.\"\"\",\n",
    "    \"\"\"Frontier is a HPE Cray EX supercomputer located at the Oak Ridge Leadership Computing Facility. \"\"\",\n",
    "    \"\"\"Each Frontier compute node consists of [1x] 64-core AMD “Optimized 3rd Gen EPYC” CPU (with 2 hardware threads per physical core) with access to 512 GB of DDR4 memory. Each node also contains [4x] AMD MI250X, each with 2 Graphics Compute Dies (GCDs) for a total of 8 GCDs per node.\"\"\",\n",
    "    \"\"\"system interconnect of frontier is that the Frontier nodes are connected with [4x] HPE Slingshot 200 Gbps (25 GB/s) NICs providing a node-injection bandwidth of 800 Gbps (100 GB/s).\"\"\",\n",
    "    \"\"\"File systems of frontier is that Frontier is connected to Orion, a parallel filesystem based on Lustre and HPE ClusterStor, with a 679 PB usable namespace (/lustre/orion/).\"\"\",\n",
    "])\n",
    "\n",
    "print(\"Similarity:\", util.dot_score(query_embedding, texts_embedding))\n",
    "print(\"Similarity:\", util.cos_sim(query_embedding, texts_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7fe51-b44c-4484-8e80-d57b617ba382",
   "metadata": {},
   "source": [
    "## UAE-Large-V1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b6c372d-fbb9-43b3-a62c-d95039ae120f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b95b0bf2-be66-4fb7-8d68-3342b6e0fa9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[174.6098, 236.6645, 242.2771, 186.1550, 180.4875]])\n",
      "Similarity: tensor([[0.5718, 0.7040, 0.7826, 0.5898, 0.5810]])\n"
     ]
    }
   ],
   "source": [
    "from angle_emb import AnglE\n",
    "\n",
    "angle = AnglE.from_pretrained('WhereIsAI/UAE-Large-V1', pooling_strategy='cls').cuda()\n",
    "query_embedding = angle.encode('what is the cpu type on frontier')\n",
    "texts_embedding = angle.encode([\n",
    "    \"\"\"scheduling policy of frontier is that in a simple batch queue system, jobs run in a first-in, first-out (FIFO) order.\"\"\",\n",
    "    \"\"\"Frontier is a HPE Cray EX supercomputer located at the Oak Ridge Leadership Computing Facility. \"\"\",\n",
    "    \"\"\"Each Frontier compute node consists of [1x] 64-core AMD “Optimized 3rd Gen EPYC” CPU (with 2 hardware threads per physical core) with access to 512 GB of DDR4 memory. Each node also contains [4x] AMD MI250X, each with 2 Graphics Compute Dies (GCDs) for a total of 8 GCDs per node.\"\"\",\n",
    "    \"\"\"system interconnect of frontier is that the Frontier nodes are connected with [4x] HPE Slingshot 200 Gbps (25 GB/s) NICs providing a node-injection bandwidth of 800 Gbps (100 GB/s).\"\"\",\n",
    "    \"\"\"File systems of frontier is that Frontier is connected to Orion, a parallel filesystem based on Lustre and HPE ClusterStor, with a 679 PB usable namespace (/lustre/orion/).\"\"\",\n",
    "])\n",
    "\n",
    "print(\"Similarity:\", util.dot_score(query_embedding, texts_embedding))\n",
    "print(\"Similarity:\", util.cos_sim(query_embedding, texts_embedding))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
