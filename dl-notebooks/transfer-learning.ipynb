{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d7fb26-5c01-4f16-a854-7698be5b25e1",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "## Concept\n",
    "\n",
    "Learning Task A has been trained with large amount of data; Now apply that\n",
    "trained model to Task B, and hoping that it can:\n",
    "* learn better\n",
    "* learn faster\n",
    "\n",
    "\n",
    "## Why transfer learning work?\n",
    "\n",
    "Transfer learning works by the assumption that Task A and B carries enough\n",
    "similarities such that the features or model learned from Task A are equally\n",
    "useful to Task B. For example, training on generic object recognization are\n",
    "applied to radiology images for cancer detection; generic speech recognization\n",
    "model used for specific wake word (Andrew Ng)\n",
    "\n",
    "## When does transfer learning make sense?\n",
    "\n",
    "* Task A has a lot more training data than Task B.\n",
    "\n",
    "- Task A and Task B have same input.\n",
    "\n",
    "## How is it done?\n",
    "\n",
    "One way of doing transferred learning is to take away the last layer in training model of A, along with\n",
    "associated weights; Add a new layer with random weights. Re-train **only** the last\n",
    "layer with training data from Task B.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
