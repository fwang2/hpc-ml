{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# !pip install graphviz\n",
    "#\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorboard as tb\n",
    "from torchviz import make_dot\n",
    "v = torch.tensor(1.0, requires_grad=True)\n",
    "make_dot(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "FileNotFoundError                         Traceback (most recent call last)",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/graphviz/backend/execute.py:79, in run_check(cmd, input_lines, encoding, quiet, **kwargs)\n     78         kwargs['stdout'] = kwargs['stderr'] = subprocess.PIPE\n---> 79     proc = _run_input_lines(cmd, input_lines, kwargs=kwargs)\n     80 else:\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/graphviz/backend/execute.py:99, in _run_input_lines(cmd, input_lines, kwargs)\n     98 def _run_input_lines(cmd, input_lines, *, kwargs):\n---> 99     popen = subprocess.Popen(cmd, stdin=subprocess.PIPE, **kwargs)\n    101     stdin_write = popen.stdin.write\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/subprocess.py:858, in Popen.__init__(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\n    855             self.stderr = io.TextIOWrapper(self.stderr,\n    856                     encoding=encoding, errors=errors)\n--> 858     self._execute_child(args, executable, preexec_fn, close_fds,\n    859                         pass_fds, cwd, env,\n    860                         startupinfo, creationflags, shell,\n    861                         p2cread, p2cwrite,\n    862                         c2pread, c2pwrite,\n    863                         errread, errwrite,\n    864                         restore_signals, start_new_session)\n    865 except:\n    866     # Cleanup if the child failed starting.\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/subprocess.py:1704, in Popen._execute_child(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\n   1703         err_msg = os.strerror(errno_num)\n-> 1704     raise child_exception_type(errno_num, err_msg, err_filename)\n   1705 raise child_exception_type(err_msg)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "ExecutableNotFound                        Traceback (most recent call last)",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/IPython/core/formatters.py:972, in MimeBundleFormatter.__call__(self, obj, include, exclude)\n    969     method = get_real_method(obj, self.print_method)\n    971     if method is not None:\n--> 972         return method(include=include, exclude=exclude)\n    973     return None\n    974 else:\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/graphviz/jupyter_integration.py:98, in JupyterIntegration._repr_mimebundle_(self, include, exclude, **_)\n     96 include = set(include) if include is not None else {self._jupyter_mimetype}\n     97 include -= set(exclude or [])\n---> 98 return {mimetype: getattr(self, method_name)()\n     99         for mimetype, method_name in MIME_TYPES.items()\n    100         if mimetype in include}\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/graphviz/jupyter_integration.py:98, in <dictcomp>(.0)\n     96 include = set(include) if include is not None else {self._jupyter_mimetype}\n     97 include -= set(exclude or [])\n---> 98 return {mimetype: getattr(self, method_name)()\n     99         for mimetype, method_name in MIME_TYPES.items()\n    100         if mimetype in include}\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/graphviz/jupyter_integration.py:112, in JupyterIntegration._repr_image_svg_xml(self)\n    110 def _repr_image_svg_xml(self) -> str:\n    111     \"\"\"Return the rendered graph as SVG string.\"\"\"\n--> 112     return self.pipe(format='svg', encoding=SVG_ENCODING)\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/graphviz/piping.py:104, in Pipe.pipe(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\n     55 def pipe(self,\n     56          format: typing.Optional[str] = None,\n     57          renderer: typing.Optional[str] = None,\n   (...)\n     61          engine: typing.Optional[str] = None,\n     62          encoding: typing.Optional[str] = None) -> typing.Union[bytes, str]:\n     63     \"\"\"Return the source piped through the Graphviz layout command.\n     64 \n     65     Args:\n   (...)\n    102         '<?xml version='\n    103     \"\"\"\n--> 104     return self._pipe_legacy(format,\n    105                              renderer=renderer,\n    106                              formatter=formatter,\n    107                              neato_no_op=neato_no_op,\n    108                              quiet=quiet,\n    109                              engine=engine,\n    110                              encoding=encoding)\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/graphviz/_tools.py:171, in deprecate_positional_args.<locals>.decorator.<locals>.wrapper(*args, **kwargs)\n    162     wanted = ', '.join(f'{name}={value!r}'\n    163                        for name, value in deprecated.items())\n    164     warnings.warn(f'The signature of {func.__name__} will be reduced'\n    165                   f' to {supported_number} positional args'\n    166                   f' {list(supported)}: pass {wanted}'\n    167                   ' as keyword arg(s)',\n    168                   stacklevel=stacklevel,\n    169                   category=category)\n--> 171 return func(*args, **kwargs)\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/graphviz/piping.py:121, in Pipe._pipe_legacy(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\n    112 @_tools.deprecate_positional_args(supported_number=2)\n    113 def _pipe_legacy(self,\n    114                  format: typing.Optional[str] = None,\n   (...)\n    119                  engine: typing.Optional[str] = None,\n    120                  encoding: typing.Optional[str] = None) -> typing.Union[bytes, str]:\n--> 121     return self._pipe_future(format,\n    122                              renderer=renderer,\n    123                              formatter=formatter,\n    124                              neato_no_op=neato_no_op,\n    125                              quiet=quiet,\n    126                              engine=engine,\n    127                              encoding=encoding)\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/graphviz/piping.py:149, in Pipe._pipe_future(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\n    146 if encoding is not None:\n    147     if codecs.lookup(encoding) is codecs.lookup(self.encoding):\n    148         # common case: both stdin and stdout need the same encoding\n--> 149         return self._pipe_lines_string(*args, encoding=encoding, **kwargs)\n    150     try:\n    151         raw = self._pipe_lines(*args, input_encoding=self.encoding, **kwargs)\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/graphviz/backend/piping.py:212, in pipe_lines_string(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\n    206 cmd = dot_command.command(engine, format,\n    207                           renderer=renderer,\n    208                           formatter=formatter,\n    209                           neato_no_op=neato_no_op)\n    210 kwargs = {'input_lines': input_lines, 'encoding': encoding}\n--> 212 proc = execute.run_check(cmd, capture_output=True, quiet=quiet, **kwargs)\n    213 return proc.stdout\n",
      "File /ccs/proj/gen150/fwang2/pt-cuda11/lib/python3.8/site-packages/graphviz/backend/execute.py:84, in run_check(cmd, input_lines, encoding, quiet, **kwargs)\n     82 except OSError as e:\n     83     if e.errno == errno.ENOENT:\n---> 84         raise ExecutableNotFound(cmd) from e\n     85     raise\n     87 if not quiet and proc.stderr:\n",
      "ExecutableNotFound: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f1b15c6d190>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"]+= os.pathsep + \"/ccs/proj/gen150/fwang2/pt-cuda11/bin\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorboard as tb\n",
    "\n",
    "# setup\n",
    "# conda install graphviz\n",
    "# pip install torchviz\n",
    "#\n",
    "# verify torchviz\n",
    "\n",
    "\n",
    "from torchviz import make_dot\n",
    "v = torch.tensor(1.0, requires_grad=True)\n",
    "make_dot(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz torchviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ch00 Visualizing Gradient Descent\n",
    "\n",
    "\n",
    "Github code: https://github.com/dvgodoy/PyTorchStepByStep/blob/master/Chapter01.ipynb\n",
    "\n",
    "\n",
    "This book uses: \n",
    "\n",
    "$$ y = b + wx + \\epsilon $$\n",
    "\n",
    "that is, feature ($x$) to predict a label $y$. The **parameter** $b$ is the bias, which tell us the expected value of $y$ when $x=0$; **parameter** $w$ or the weights tell us how much $y$ increaes on average, if we increase $x$ by one unit. The last term is there to account for inherent **noise**, that is the error we can't get rid of.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prep the synthetic data\n",
    "\n",
    "1) generate N number of random values (0,1)\n",
    "2) add each with some noise from \"standard normal\"\n",
    "3) split train and val by 80% and 20% (indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic data generation\n",
    "true_b = 1\n",
    "true_w = 2\n",
    "N = 100\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(N, 1) # random value between 0 and 1\n",
    "\n",
    "epsilon = (0.1 * np.random.randn(N,1)) # from normal distribution\n",
    "\n",
    "y = true_b + true_w * x + epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shuffles the indices\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# use first 80 random indices for train\n",
    "train_idx = idx[:int(N * 0.8)]\n",
    "\n",
    "# use the remaining indices for validation\n",
    "\n",
    "val_idx = idx[int(N*0.8):]\n",
    "\n",
    "# generates train and validataion sets\n",
    "\n",
    "x_train , y_train = x[train_idx], y[train_idx]\n",
    "x_val , y_val = x[val_idx], y[val_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def figure1(x_train, y_train, x_val, y_val):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    ax[0].scatter(x_train, y_train)\n",
    "    ax[0].set_xlabel('x')\n",
    "    ax[0].set_ylabel('y')\n",
    "    ax[0].set_ylim([0, 3.1])\n",
    "    ax[0].set_title('Generated Data - Train')\n",
    "\n",
    "    ax[1].scatter(x_val, y_val, c='r')\n",
    "    ax[1].set_xlabel('x')\n",
    "    ax[1].set_ylabel('y')\n",
    "    ax[1].set_ylim([0, 3.1])\n",
    "    ax[1].set_title('Generated Data - Validation')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1(x_train,y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# step 0 random init\n",
    "# initialize the parameters \"b\" and \"w\" randomly\n",
    "\n",
    "np.random.seed(42)\n",
    "b = np.random.randn(1)\n",
    "w = np.random.randn(1)\n",
    "print(b,w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: compute model predictions\n",
    "\n",
    "forward pass - compute the model predition using current value of w anb b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = b + w * x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### step 2: compute the loss\n",
    "\n",
    "for a regression program, the loss is given by Mean Squared Error (MSE), that is, the average of all squared erros.\n",
    "\n",
    "in the code below, we are using all data points of the training set to compute the loss, so $n = N = 80$, so this is batch gradient descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = (yhat - y_train)\n",
    "\n",
    "# we now compute MSE\n",
    "\n",
    "loss = (error **2).mean()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: Compute the gradient\n",
    "\n",
    "a **gradient** is a **partial derivative**. It tells you how much a **given quantity changes**, when you slightly vary the **other quantity**. Here the **given quantity** is usually the loss, the **other quanity** is some parameter under consideration, in this case, that is $b$ and $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_grad = 2 * error.mean()\n",
    "w_grad = 2 * (x_train * error).mean()\n",
    "print(b_grad, w_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4: update parameters\n",
    "\n",
    "in this step, we use gradient to update the parameters. we use negative sign of the gradient for the update.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1 # learning rate, \"eta\" in Greek letter\n",
    "print(b, w)\n",
    "\n",
    "# update parameter\n",
    "\n",
    "b = b - lr * b_grad\n",
    "w = w - lr * w_grad\n",
    "print(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 5: repeat\n",
    "\n",
    "we now go back to step 1 and restart the process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of Epoch\n",
    "\n",
    "A epoch is complete whenever every point in the training set (N) has already been use in all steps: forward pass, computing the loss, computing the gradient, and update the parameters.\n",
    "\n",
    "The number of **update** varies:\n",
    "\n",
    "* for batch ($n=N$), one epoch is the same as **one update**\n",
    "* for stochastic ($n=1$), one epoch means $N$ updates\n",
    "* for mini-batch (of size $n$), one epoch has $\\frac{N}{n}$ updates\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss vs. Error\n",
    "\n",
    "The **error** is the difference between the **actual value** and **predicted value** computed for a single data point. For for $i-th$ data point:\n",
    "\n",
    "$$\\text{error}_i = \\hat{y_i} - y_i$$\n",
    "\n",
    "The **losss**, on the other hand, it some sort of **aggregation** of errors for a set of data points.\n",
    "\n",
    "* If we use **all points** in the training dataset, $n=N$ to compute the loss, we are performing a **batch gradient descent**.\n",
    "\n",
    "* If we use a **single point** ($n=1$) each time, it will be stochastic gradient descent.\n",
    "\n",
    "* Anything else in between 1 and $N$, that is **mini-batch gradient descent**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Metrics for Regression: Mean Squared Error (MSE)\n",
    "\n",
    "\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} {error_i}^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Pytorch \n",
    "\n",
    "* A **scalar** has zero dimensions\n",
    "* A **vector** has 1 dimension\n",
    "* A **matrix** has 2 dimensions\n",
    "* A **tensor** has 3 or more dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "scalar = torch.tensor(3.14)\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "matrix = torch.ones((2,3), dtype=torch.float)\n",
    "tensor = torch.randn((2,3,4), dtype=torch.float)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scalar.size(), scalar.shape)\n",
    "print(tensor.size(), tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a different view\n",
    "\n",
    "same_matrix = matrix.view(1,6)\n",
    "print(matrix)\n",
    "print(same_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "\"Deep Learning with PyTorch\" Step by Step Guide\n",
    "published around 2021, https://github.com/dvgodoy/PyTorchStepByStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-cuda11",
   "language": "python",
   "name": "pt-cuda11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
